{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # 1. Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "\n",
    "    # 2. Create dense vector collection\n",
    "    logging.info(\"Creating collection...\")\n",
    "    dim = 768\n",
    "    metric_type = \"L2\"  # or \"IP\"\n",
    "    collection = Collection(\n",
    "        \"dense_test\",\n",
    "        CollectionSchema([\n",
    "            FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim)\n",
    "        ]),\n",
    "        consistency_level=\"Strong\" \n",
    "    )\n",
    "    logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "    # 3. Create index and load\n",
    "    logging.info(\"Creating index...\")\n",
    "    collection.create_index(\n",
    "        \"vector\",\n",
    "        {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "    )\n",
    "    collection.load()\n",
    "    logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "    # 4. Insert dense vectors\n",
    "    logging.info(\"Generating and inserting vectors...\")\n",
    "    vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "    collection.insert([list(range(100)), vectors.tolist()])\n",
    "    logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "    # 5. Verify Query\n",
    "    logging.info(\"Running query...\")\n",
    "    res = collection.query(expr=\"id == 0\", output_fields=[\"vector\"])\n",
    "    logging.info(\"Query results:\")\n",
    "    print(f\"Query returned {len(res)} results:\")\n",
    "    for idx, result in enumerate(res):\n",
    "        print(f\"Result {idx}: ID={result['id']}, Vector={result['vector'][:5]}...\")  # Show first 5 elements\n",
    "\n",
    "    # 6. Verify Search\n",
    "    logging.info(\"Running search...\")\n",
    "    search_result = collection.search(\n",
    "        vectors[:1].tolist(),\n",
    "        \"vector\",\n",
    "        {\"metric_type\": metric_type, \"params\": {\"nprobe\": 10}},\n",
    "        limit=3,\n",
    "        output_fields=[\"vector\"]\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Search results:\")\n",
    "    print(f\"\\nSearch returned {len(search_result[0])} results:\")\n",
    "    for idx, hit in enumerate(search_result[0]):\n",
    "        print(f\"Rank {idx+1}: ID={hit.id}, Distance={hit.distance:.4f}\")\n",
    "        print(f\"Vector: {hit.entity.fields['vector'][:5]}...\\n\")\n",
    "\n",
    "    # Cleanup\n",
    "    logging.info(\"Cleaning up...\")\n",
    "    utility.drop_collection(\"dense_test\")\n",
    "    logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "from scipy.sparse import random as sparse_random\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # 1. Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "\n",
    "    # 2. Create dense vector collection\n",
    "    logging.info(\"Creating collection...\")\n",
    "    dim = 768\n",
    "    metric_type = \"L2\"  # or \"IP\"\n",
    "    collection = Collection(\n",
    "        \"sparse_test\",\n",
    "        CollectionSchema([\n",
    "            FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim)\n",
    "        ]),\n",
    "        consistency_level=\"Strong\" \n",
    "    )\n",
    "    logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "    # 3. Create index and load\n",
    "    logging.info(\"Creating index...\")\n",
    "    collection.create_index(\n",
    "        \"vector\",\n",
    "        {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "    )\n",
    "    collection.load()\n",
    "    logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "    # 4. Insert dense vectors\n",
    "    logging.info(\"Generating and inserting vectors...\")\n",
    "    vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "    collection.insert([list(range(100)), vectors.tolist()])\n",
    "    logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "    # 5. Verify Query\n",
    "    logging.info(\"Running query...\")\n",
    "    res = collection.query(expr=\"id == 0\", output_fields=[\"vector\"])\n",
    "    logging.info(\"Query results:\")\n",
    "    print(f\"Query returned {len(res)} results:\")\n",
    "    for idx, result in enumerate(res):\n",
    "        print(f\"Result {idx}: ID={result['id']}, Vector={result['vector'][:5]}...\")  # Show first 5 elements\n",
    "\n",
    "    # 6. Verify Search\n",
    "    logging.info(\"Running search...\")\n",
    "    search_result = collection.search(\n",
    "        vectors[:1].tolist(),\n",
    "        \"vector\",\n",
    "        {\"metric_type\": metric_type, \"params\": {\"nprobe\": 10}},\n",
    "        limit=3,\n",
    "        output_fields=[\"vector\"]\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Search results:\")\n",
    "    print(f\"\\nSearch returned {len(search_result[0])} results:\")\n",
    "    for idx, hit in enumerate(search_result[0]):\n",
    "        print(f\"Rank {idx+1}: ID={hit.id}, Distance={hit.distance:.4f}\")\n",
    "        print(f\"Vector: {hit.entity.fields['vector'][:5]}...\\n\")\n",
    "\n",
    "    # Cleanup\n",
    "    logging.info(\"Cleaning up...\")\n",
    "    utility.drop_collection(\"sparse_test\")\n",
    "    logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "from scipy.sparse import random as sparse_random\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "    \n",
    "    \n",
    "    # Test multiple dimensions\n",
    "    dimensions = [2, 64, 256, 1024, 4096]\n",
    "    metric_type = \"L2\"\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        logging.info(f\"\\n{'='*30} Testing Dimension: {dim} {'='*30}\")\n",
    "\n",
    "        # Create dense vector collection\n",
    "        logging.info(\"Creating collection...\")\n",
    "        dim = 768\n",
    "        metric_type = \"L2\"  # or \"IP\"\n",
    "        collection = Collection(\n",
    "            \"dim_test\",\n",
    "            CollectionSchema([\n",
    "                FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "                FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim)\n",
    "            ]),\n",
    "            consistency_level=\"Strong\" \n",
    "        )\n",
    "        logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "        # Create index and load\n",
    "        logging.info(\"Creating index...\")\n",
    "        collection.create_index(\n",
    "            \"vector\",\n",
    "            {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "        )\n",
    "        collection.load()\n",
    "        logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "        # Insert dense vectors\n",
    "        logging.info(\"Generating and inserting vectors...\")\n",
    "        vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "        collection.insert([list(range(100)), vectors.tolist()])\n",
    "        logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "        # Verify Query\n",
    "        logging.info(\"Running query...\")\n",
    "        res = collection.query(expr=\"id == 0\", output_fields=[\"vector\"])\n",
    "        logging.info(\"Query results:\")\n",
    "        print(f\"Query returned {len(res)} results:\")\n",
    "        for idx, result in enumerate(res):\n",
    "            print(f\"Result {idx}: ID={result['id']}, Vector={result['vector'][:5]}...\")  # Show first 5 elements\n",
    "\n",
    "        # Verify Search\n",
    "        logging.info(\"Running search...\")\n",
    "        search_result = collection.search(\n",
    "            vectors[:1].tolist(),\n",
    "            \"vector\",\n",
    "            {\"metric_type\": metric_type, \"params\": {\"nprobe\": 10}},\n",
    "            limit=3,\n",
    "            output_fields=[\"vector\"]\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Search results:\")\n",
    "        print(f\"\\nSearch returned {len(search_result[0])} results:\")\n",
    "        for idx, hit in enumerate(search_result[0]):\n",
    "            print(f\"Rank {idx+1}: ID={hit.id}, Distance={hit.distance:.4f}\")\n",
    "            print(f\"Vector: {hit.entity.fields['vector'][:5]}...\\n\")\n",
    "\n",
    "        # Cleanup\n",
    "        logging.info(\"Cleaning up...\")\n",
    "        utility.drop_collection(\"dim_test\")\n",
    "        logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # 1. Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "\n",
    "    # 2. Create dense vector collection\n",
    "    logging.info(\"Creating collection...\")\n",
    "    dim = 768\n",
    "    metric_type = \"L2\"  # or \"IP\"\n",
    "    collection = Collection(\n",
    "        \"scalar_test\",\n",
    "        CollectionSchema([\n",
    "            FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim),\n",
    "            FieldSchema(\"str_field\", DataType.VARCHAR, max_length=200),\n",
    "            FieldSchema(\"float_field\", DataType.FLOAT),\n",
    "            FieldSchema(\"int_field\", DataType.INT32),\n",
    "            FieldSchema(\"bool_field\", DataType.BOOL),\n",
    "            FieldSchema(\"ts_field\", DataType.INT64)  # Timestamp stored as INT64\n",
    "        ]),\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "    logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "    # 3. Create index and load\n",
    "    logging.info(\"Creating index...\")\n",
    "    collection.create_index(\n",
    "        \"vector\",\n",
    "        {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "    )\n",
    "    collection.load()\n",
    "    logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "    # 4. Insert dense vectors\n",
    "    logging.info(\"Generating and inserting vectors...\")\n",
    "    vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "    data = [\n",
    "        list(range(100)),  # IDs\n",
    "        vectors,  # Vectors\n",
    "        [f\"str_{i}\" + \"a\"*(i%10) for i in range(100)],  # VARCHAR\n",
    "        np.random.rand(100).tolist(),  # FLOAT values\n",
    "        list(np.random.randint(0, 10000, 100)),  # INT32\n",
    "        [bool(i%2) for i in range(100)],  # BOOL\n",
    "        [int(1672531200 + i*3600) for i in range(100)]  # INT64 timestamps (hourly)\n",
    "    ]\n",
    "    collection.insert(data)\n",
    "    logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "    # 5. Verify Query\n",
    "    logging.info(\"Querying with scalar conditions...\")\n",
    "    res = collection.query(\n",
    "        # expr=\"id == 0\",\n",
    "        # expr=\"bool_field == True\",\n",
    "        expr=\"float_field > 0.5 and bool_field == True\",\n",
    "        # expr=\"str_field like 'str_1%' and float_field > 0.5 and bool_field == True\",\n",
    "        output_fields=[\"*\"]\n",
    "    )\n",
    "    print(\"\\nScalar query results:\")\n",
    "    for r in res[:3]:  # Print first 3 results\n",
    "        print(f\"ID:{r['id']} | str:{r['str_field']} | float:{r['float_field']:.2f} | \"\n",
    "              f\"int:{r['int_field']} | bool:{r['bool_field']} | ts:{r['ts_field']}\")\n",
    "\n",
    "    # Cleanup\n",
    "    logging.info(\"Cleaning up...\")\n",
    "    utility.drop_collection(\"scalar_test\")\n",
    "    logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # 1. Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "\n",
    "    # 2. Create dense vector collection\n",
    "    logging.info(\"Creating collection...\")\n",
    "    dim = 768\n",
    "    metric_type = \"L2\"  # or \"IP\"\n",
    "    collection = Collection(\n",
    "        \"float_vector_test\",\n",
    "        CollectionSchema([\n",
    "            FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim)\n",
    "        ]),\n",
    "        consistency_level=\"Strong\" \n",
    "    )\n",
    "    logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "    # 3. Create index and load\n",
    "    logging.info(\"Creating index...\")\n",
    "    collection.create_index(\n",
    "        \"vector\",\n",
    "        {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "    )\n",
    "    collection.load()\n",
    "    logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "    # 4. Insert dense vectors\n",
    "    logging.info(\"Generating and inserting vectors...\")\n",
    "    vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "    collection.insert([list(range(100)), vectors.tolist()])\n",
    "    logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "    # 5. Verify Query\n",
    "    logging.info(\"Running query...\")\n",
    "    res = collection.query(expr=\"id == 0\", output_fields=[\"vector\"])\n",
    "    logging.info(\"Query results:\")\n",
    "    print(f\"Query returned {len(res)} results:\")\n",
    "    for idx, result in enumerate(res):\n",
    "        print(f\"Result {idx}: ID={result['id']}, Vector={result['vector'][:5]}...\")  # Show first 5 elements\n",
    "\n",
    "    # 6. Verify Search\n",
    "    logging.info(\"Running search...\")\n",
    "    search_result = collection.search(\n",
    "        vectors[:1].tolist(),\n",
    "        \"vector\",\n",
    "        {\"metric_type\": metric_type, \"params\": {\"nprobe\": 10}},\n",
    "        limit=3,\n",
    "        output_fields=[\"vector\"]\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Search results:\")\n",
    "    print(f\"\\nSearch returned {len(search_result[0])} results:\")\n",
    "    for idx, hit in enumerate(search_result[0]):\n",
    "        print(f\"Rank {idx+1}: ID={hit.id}, Distance={hit.distance:.4f}\")\n",
    "        print(f\"Vector: {hit.entity.fields['vector'][:5]}...\\n\")\n",
    "\n",
    "    # Cleanup\n",
    "    logging.info(\"Cleaning up...\")\n",
    "    utility.drop_collection(\"float_vector_test\")\n",
    "    logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "try:\n",
    "    # 1. Connect to Milvus\n",
    "    logging.info(\"Connecting to Milvus server...\")\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    logging.info(\"Successfully connected to Milvus\")\n",
    "\n",
    "    utility.drop_collection(\"json_test\")\n",
    "    # 2. Create dense vector collection\n",
    "    logging.info(\"Creating collection...\")\n",
    "    dim = 768\n",
    "    metric_type = \"L2\"  # or \"IP\"\n",
    "    collection = Collection(\n",
    "        \"json_test\",\n",
    "        CollectionSchema([\n",
    "            FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=dim),\n",
    "            FieldSchema(\"metadata\", DataType.JSON)\n",
    "        ]),\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "    logging.info(f\"Collection created: {collection.name}\")\n",
    "\n",
    "    # 3. Create index and load\n",
    "    logging.info(\"Creating index...\")\n",
    "    collection.create_index(\n",
    "        \"vector\",\n",
    "        {\"index_type\": \"IVF_FLAT\", \"metric_type\": metric_type, \"params\": {\"nlist\": 16}}\n",
    "    )\n",
    "    collection.load()\n",
    "    logging.info(\"Index created and collection loaded\")\n",
    "\n",
    "    # 4. Insert dense vectors\n",
    "    logging.info(\"Generating and inserting vectors...\")\n",
    "    vectors = np.random.randn(100, dim).astype(np.float32)\n",
    "    data = [\n",
    "        list(range(100)),\n",
    "        vectors,\n",
    "        [{\n",
    "            \"title\": f\"doc_{i}\",\n",
    "            \"tags\": [\"tag1\", \"tag2\"] if i%2 else [\"tag3\"],\n",
    "            \"stats\": {\"views\": i*10, \"rating\": round(np.random.uniform(1, 5), 1)}\n",
    "        } for i in range(100)]\n",
    "    ]\n",
    "    collection.insert(data)\n",
    "\n",
    "    logging.info(f\"Inserted {len(vectors)} vectors\")\n",
    "\n",
    "    # 5. Verify JSON query\n",
    "    logging.info(\"Querying JSON data...\")\n",
    "    res = collection.query(\n",
    "        expr=\"metadata['title'] == 'doc_0' and metadata['stats']['rating'] > 0\",\n",
    "        output_fields=[\"metadata\", \"id\"]\n",
    "    )\n",
    "    print(\"\\nJSON query results:\")\n",
    "    for r in res:\n",
    "        print(f\"ID:{r['id']} | Metadata:{r['metadata']}\")\n",
    "\n",
    "    # 6. Verify JSON in search results\n",
    "    search_result = collection.search(\n",
    "        data[1][:1],  # Use first vector\n",
    "        \"vector\",\n",
    "        param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n",
    "        limit=3,\n",
    "        output_fields=[\"metadata\"]\n",
    "    )\n",
    "    print(\"\\nJSON in search results:\")\n",
    "    for hit in search_result[0]:\n",
    "        print(f\"ID:{hit.id} | Metadata:{hit.entity.fields['metadata']}\")\n",
    "\n",
    "    # Cleanup\n",
    "    logging.info(\"Cleaning up...\")\n",
    "    utility.drop_collection(\"float_vector_test\")\n",
    "    logging.info(\"Collection dropped successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred: {str(e)}\", exc_info=True)\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
